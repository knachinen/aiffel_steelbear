{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3fc4b5b",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "- [ ] Pascal VOC 데이터셋을 학습해 세그멘테이션을 하는 UNet 모델 만들기\n",
    "- [ ] Tensorboard.dev를 통해 학습 결과 공유하기\n",
    "- [ ] CAM 기법으로 학습된 결과 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c3015",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956fe024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('nateraw/pascal-voc-2012', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a48bb",
   "metadata": {},
   "source": [
    "# 데이터셋 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1d7dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaffe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac329e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset['image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee432ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataset['image'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bfb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['image'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca71fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "image_bytes = io.BytesIO(dataset['image'][1]['bytes'])\n",
    "image = Image.open(image_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb1ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(image.size)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "image_tensor = tf.convert_to_tensor(image, dtype='float32')\n",
    "print(image_tensor.shape)\n",
    "print(image_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56dfd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bytes_to_numpy(bytes_string, image_size=(280, 280)):\n",
    "    image_bytes = io.BytesIO(bytes_string)\n",
    "    image = Image.open(image_bytes).resize(image_size)\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2fad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(dataset['mask']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b776172",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset['mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19daf30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img = bytes_to_numpy(dataset['mask'][0]['bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a770055",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecacc807",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tf.cast(mask_img, 'uint8'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2d555",
   "metadata": {},
   "source": [
    "# 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd54e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference: https://d2l.ai/chapter_computer-vision/semantic-segmentation-and-dataset.html\n",
    "\n",
    "VOC_COLORMAP = np.array([[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]])\n",
    "\n",
    "VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n",
    "               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n",
    "               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']\n",
    "\n",
    "border = np.array([224, 224, 192])\n",
    "num_classes = len(VOC_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aac325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int_labels(image_numpy):\n",
    "    original_shape = image_numpy.shape\n",
    "    image_numpy = image_numpy.reshape(-1, 3)\n",
    "    labels = np.zeros(image_numpy.shape[0])\n",
    "    for i, rgb in enumerate(image_numpy):\n",
    "        if (rgb == border).all():\n",
    "            labels[i] = 0.\n",
    "        else:\n",
    "            colormap_matched = (rgb == VOC_COLORMAP).all(axis=-1)\n",
    "            labels[i] = np.argmax(colormap_matched.astype('float32'))\n",
    "    return labels.reshape(original_shape[:-1])\n",
    "\n",
    "def to_image_array(row):\n",
    "    new_row = {}\n",
    "    new_row['image'] = bytes_to_numpy(row['image']['bytes'])\n",
    "    new_row['mask'] = bytes_to_numpy(row['mask']['bytes'])\n",
    "    new_row['mask'] = convert_to_int_labels(new_row['mask'])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd7e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(to_image_array, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32f4c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.to_tf_dataset(columns=['image'],\n",
    "                                label_cols=['mask'],\n",
    "                                batch_size=256,\n",
    "                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cc478",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, masks in dataset:\n",
    "    print(images[0].shape)\n",
    "    print(images[0].dtype)\n",
    "    print(masks[0].shape)\n",
    "    print(masks[0].dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba6ec9c",
   "metadata": {},
   "source": [
    "# UNet 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b38c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "down_samplings = []\n",
    "\n",
    "inputs = keras.Input(shape=(280, 280, 3))\n",
    "\n",
    "x = inputs\n",
    "for num_filters in [64, 128, 256, 512]:\n",
    "    x = layers.Conv2D(num_filters, 3, activation='relu')(x)\n",
    "    x = layers.Conv2D(num_filters, 3, activation='relu')(x)\n",
    "    down_samplings.append(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.Conv2D(1024, 3)(x)\n",
    "x = layers.Conv2D(1024, 3)(x)\n",
    "\n",
    "for num_filters in [512, 256, 128, 64]:\n",
    "    x = layers.Conv2DTranspose(num_filters, strides=2, padding='same', activation='relu')(x)\n",
    "    donw_conv = down_samplings.pop()\n",
    "    x = layers.Concatenate(axis=-1)([down_conv, x])\n",
    "    x = layers.Conv2D(num_filters, activation='relu')(x)\n",
    "    x = layers.Conv2D(num_filters, activation='relu')(x)\n",
    "\n",
    "outputs = layers.Conv2D(num_classes, 1, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e0d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('UNet_Pascal_VOC.keras',\n",
    "                                    save_best_only=True),\n",
    "    keras.callbacks.TensorBoard('./logs')\n",
    "]\n",
    "\n",
    "history = model.fit(dataset, epochs=20, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe43b8c",
   "metadata": {},
   "source": [
    "# tensorboard.dev로 학습 결과 공유하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad7107",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard dev upload --logdir logs \\\n",
    "    --name \"AIFFLE Main Quest 2 by SteelBear\" \\\n",
    "    --description \"Pascal VOC semantic segmentation with UNet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb0fea9",
   "metadata": {},
   "source": [
    "# Class Activation Map을 통해 모델 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ab62bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
