{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da5301bb",
   "metadata": {},
   "source": [
    "# NSMC 데이터셋 불러오기\n",
    "- [Naver Sentiment Movie Corpus](https://github.com/e9t/nsmc)\n",
    "    - 한국어로 작성된 네이버 영화 리뷰 데이터셋\n",
    "- 데이터 구성\n",
    "    - size\n",
    "        - train: 150,000\n",
    "        - test: 50,000\n",
    "    - columns\n",
    "        - id\n",
    "            - 네이버에서 붙인 리뷰 id\n",
    "        - document\n",
    "            - string, 리뷰 텍스트\n",
    "        - label\n",
    "            - int, 리뷰에 대한 감정 라벨\n",
    "            - 긍정적: 1, 부정적: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69824930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset nsmc (/aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3666648e523a4875bf22b79ca2039c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('nsmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b271ee52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 150000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 수 확인\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4edee96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/테스트 데이터셋 분리\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa25c8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 9976970\n",
      "document : 아 더빙.. 진짜 짜증나네요 목소리\n",
      "label : 0\n",
      "\n",
      "id : 3819312\n",
      "document : 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
      "label : 1\n",
      "\n",
      "id : 10265843\n",
      "document : 너무재밓었다그래서보는것을추천한다\n",
      "label : 0\n",
      "\n",
      "id : 9045019\n",
      "document : 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
      "label : 0\n",
      "\n",
      "id : 6483659\n",
      "document : 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
      "label : 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 위의 5개 데이터 확인하기\n",
    "for i in range(5):\n",
    "    for col in train_dataset.column_names:\n",
    "        print(col, \":\", train_dataset[col][i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625bc7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 리뷰 문장의 길이 분포 그래프 그리기\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_lengths = np.array(list(map(len, train_dataset['document'])))\n",
    "\n",
    "lengths, counts = np.unique(train_lengths, return_counts=True)\n",
    "plt.bar(x=lengths, height=counts)\n",
    "plt.xlabel('length of document')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79df1c3",
   "metadata": {},
   "source": [
    "# 모델, 토크나이저 불러오기\n",
    "- [klue/bert-base](https://huggingface.co/klue/bert-base)\n",
    "    - KLUE 데이터셋을 pre-train한 BERT 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f8f702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model과 tokenizer 불러오기\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"klue/bert-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dffdd3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>\n",
      "tokenizer: <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>\n"
     ]
    }
   ],
   "source": [
    "# 불러온 model과 tokenizer 확인하기\n",
    "print('model:', model.__class__)\n",
    "print('tokenizer:', tokenizer.__class__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79251930",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "- tokenizer로 추가되는 columns\n",
    "    - input_ids\n",
    "        - List(int), 정수로 표현된 토큰 리스트\n",
    "    - attention_mask\n",
    "        - List(int), 어텐션을 진행할 토큰 마스크\n",
    "        - 문장 토큰과 패딩 토큰을 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "514dc5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 토큰화하는 함수\n",
    "def transform(data):\n",
    "    return tokenizer(\n",
    "        data['document'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe4e662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 1376, 831, 2604, 18, 18, 4229, 9801, 2075, 2203, 2182, 4243, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'input_ids': [2, 1963, 18, 18, 18, 11811, 2178, 2088, 28883, 16516, 2776, 18, 18, 18, 18, 10737, 2156, 2015, 2446, 2232, 6758, 2118, 1380, 6074, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'input_ids': [2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'input_ids': [2, 12381, 3758, 2251, 2615, 18, 18, 7946, 4697, 2259, 1415, 2062, 18, 18, 20609, 4221, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'input_ids': [2, 3734, 2582, 2743, 2029, 2079, 26268, 2255, 2957, 4483, 2116, 21486, 2414, 3771, 5, 29493, 27135, 795, 15882, 2052, 2015, 2154, 1902, 2414, 21898, 3113, 28470, 2265, 2116, 5699, 2119, 21690, 2178, 2507, 2062, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# transform 데이터 테스트\n",
    "for i in range(5):\n",
    "    tokens = transform(train_dataset[i])\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb289f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5331c4de5b7c448b919bddc3268d210f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f1b1ab00464cf6aa8fbe1295707e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터셋 토큰화\n",
    "train_dataset = train_dataset.map(transform, batched=True)\n",
    "test_dataset = test_dataset.map(transform, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa34f640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'document', 'id', 'input_ids', 'label'],\n",
       "    num_rows: 150000\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리된 데이터셋 확인\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883ae8ee",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce26efd",
   "metadata": {},
   "source": [
    "## Dynamic Padding 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01627152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# 가중치를 저장할 위치\n",
    "output_dir = os.getenv('HOME') + '/aiffel/transformers'\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir,\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4, # 메모리 부족으로 인해 batch_size 고정\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471ad525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_find_unused_parameters=None,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=IntervalStrategy.EPOCH,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "hub_model_id=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=2e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=-1,\n",
       "log_level=-1,\n",
       "log_level_replica=-1,\n",
       "log_on_each_node=True,\n",
       "logging_dir=/aiffel/aiffel/transformers/runs/Sep15_08-33-21_wy73nz14myc73iartlx33j2ur-54bdb8549d-sgkzf,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=1,\n",
       "output_dir=/aiffel/aiffel/transformers,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=4,\n",
       "per_device_train_batch_size=4,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard'],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=/aiffel/aiffel/transformers,\n",
       "save_on_each_node=False,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.STEPS,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_legacy_prediction_loop=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d19e9857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "metric = datasets.load_metric('accuracy')\n",
    "\n",
    "# metric 함수\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1e580bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine-tuning을 위한 trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbbeeec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running training *****\n",
      "  Num examples = 150000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37500' max='37500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37500/37500 4:44:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.395100</td>\n",
       "      <td>0.389570</td>\n",
       "      <td>0.901040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-12500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-12500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-12500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-13000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-13000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-13000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-13500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-13500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-13500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-14000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-14000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-14000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-14500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-14500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-14500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-15000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-15000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-15000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-15500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-15500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-15500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-16000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-16000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-16000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-16500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-16500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-16500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-17000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-17000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-17000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-17500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-17500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-17500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-18500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-18500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-18500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-19000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-19000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-19000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-19500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-19500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-19500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-20000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-20000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-20000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-20500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-20500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-20500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-21500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-21500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-21500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-22000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-22000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-22000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-22500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-22500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-22500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-23000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-23000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-23000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-23500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-23500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-23500/pytorch_model.bin\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-24000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-24500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-24500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-24500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-25000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-25000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-25000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-25500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-25500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-25500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-26000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-26000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-26000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-26500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-26500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-26500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-27000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-27000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-27000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-27500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-27500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-27500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-28000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-28000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-28000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-28500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-28500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-28500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-29000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-29000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-29000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-29500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-29500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-29500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-30000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-30000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-30000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-30500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-30500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-30500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-31000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-31000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-31000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-31500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-31500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-31500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-32000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-32000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-32000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-32500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-32500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-32500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-33500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-33500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-33500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-34000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-34000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-34000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-34500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-34500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-34500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-35000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-35000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-35000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-35500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-35500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-35500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-36000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-36000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-36000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-36500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-36500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-36500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-37000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-37000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-37000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-37500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-37500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-37500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=37500, training_loss=0.4177820764160156, metrics={'train_runtime': 17041.4261, 'train_samples_per_second': 8.802, 'train_steps_per_second': 2.201, 'total_flos': 3.9466658304e+16, 'train_loss': 0.4177820764160156, 'epoch': 1.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 fine-tuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1ea52",
   "metadata": {},
   "source": [
    "## Dynamic Padding 추가\n",
    "- [Dynamic Padding](https://www.youtube.com/watch?v=7q5NyFT8REg)\n",
    "    - 배치별로 패딩 길이를 달리한다\n",
    "        - 배치내 가장 긴 길이를 기준으로 패딩 추가\n",
    "        - 패딩으로 낭비되는 메모리를 줄일 수 있다\n",
    "- DataCollator\n",
    "    - 데이터를 배치로 묶는 객체\n",
    "    - 모델 종류에 따라 다양한 옵션을 제공한다\n",
    "        - DataCollatorForLanguageModeling\n",
    "            - MLM task로 변환 가능\n",
    "        - DataCollatorWithPadding\n",
    "            - 원하는 방식의 Padding 방식(Padding Strategy) 지정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3df07b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cb8bb287084ee7a2f9886349d4acb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b8687c3f164cce94fe37f2d09b7876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 전처리시 패딩 미적용\n",
    "def transform_without_padding(data):\n",
    "    return tokenizer(\n",
    "        data['document'],\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "\n",
    "# 패딩 없는 데이터셋 생성\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "train_dataset = train_dataset.map(transform_without_padding, batched=True)\n",
    "test_dataset = test_dataset.map(transform_without_padding, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89276f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "# data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fee65073",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 기존 모델 삭제\n",
    "del model\n",
    "\n",
    "# pre-trained 모델 새로 불러오기\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9ff9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir,\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    #per_device_train_batch_size=4, # Dynamic Padding으로 더 큰 batch로 돌릴 수 있도록\n",
    "    #per_device_eval_batch_size=4,  # 직접 지정한 batch_size를 해제\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    group_by_length=True # 길이가 비슷한 데이터끼리 묶기\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator # data_collator 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7d4a45c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running training *****\n",
      "  Num examples = 150000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18750' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18750/18750 39:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.281505</td>\n",
       "      <td>0.902960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-12500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-12500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-12500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-13000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-13000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-13000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-13500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-13500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-13500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-14000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-14000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-14000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-14500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-14500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-14500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-15000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-15000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-15000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-15500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-15500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-15500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-16000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-16000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-16000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-16500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-16500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-16500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-17000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-17000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-17000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-17500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-17500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-17500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-18000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-18000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-18000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-18500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-18500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-18500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18750, training_loss=0.31370203816731773, metrics={'train_runtime': 2384.7069, 'train_samples_per_second': 62.901, 'train_steps_per_second': 7.863, 'total_flos': 1902112041402240.0, 'train_loss': 0.31370203816731773, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9140f4eb",
   "metadata": {},
   "source": [
    "# 학습 결과 비교\n",
    "||Dynamic Padding 없음|Dynamic Padding 적용|\n",
    "|-|-|-|\n",
    "|학습 소요 시간|4:44:00|0:39:44|\n",
    "|Training Loss|0.395100|0.258700|\n",
    "|Test Loss|0.389570|0.281505|\n",
    "|Test Accuracy|0.901040|0.902960|\n",
    "\n",
    "- Dynamic Padding을 적용함으로써 batch_size를 4에서 8로 올릴 수 있었음\n",
    "- batch_size가 커짐에 따라 소요 시간이 현저히 줄어들었고 정확도가 0.1920%p 상승"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf51e853",
   "metadata": {},
   "source": [
    "# 회고\n",
    "- fine-tuning 또한 매우 오래 걸리는 작업\n",
    "- 학습을 돌릴때 메모리 관리가 가장 중요\n",
    "    - VRAM 부족으로 미니배치 크기를 늘릴 수 없었음\n",
    "    - Dynamic Padding으로 그나마 줄여서 미니배치 크기를 조금이나마 늘릴수 있었음\n",
    "    - 전반적으로 메모리 관리가 모델 학습 시간이나 성능에도 영향을 끼친다는 것을 알게됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8638e924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
