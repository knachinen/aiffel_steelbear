{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b57422a4",
   "metadata": {},
   "source": [
    "# NSMC 데이터셋 불러오기\n",
    "- [Naver Sentiment Movie Corpus](https://github.com/e9t/nsmc)\n",
    "    - 한국어로 작성된 네이버 영화 리뷰 데이터셋\n",
    "- 데이터 구성\n",
    "    - size\n",
    "        - train: 150,000\n",
    "        - test: 50,000\n",
    "    - columns\n",
    "        - id\n",
    "            - 네이버에서 붙인 리뷰 id\n",
    "        - document\n",
    "            - string, 리뷰 텍스트\n",
    "        - label\n",
    "            - int, 리뷰에 대한 감정 라벨\n",
    "            - 긍정적: 1, 부정적: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03e847a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset nsmc (/aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7388340d529a40e58b182fac3b4a6d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('nsmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e466b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 150000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'document', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 수 확인\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c306e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/테스트 데이터셋 분리\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa90ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 9976970\n",
      "document : 아 더빙.. 진짜 짜증나네요 목소리\n",
      "label : 0\n",
      "\n",
      "id : 3819312\n",
      "document : 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
      "label : 1\n",
      "\n",
      "id : 10265843\n",
      "document : 너무재밓었다그래서보는것을추천한다\n",
      "label : 0\n",
      "\n",
      "id : 9045019\n",
      "document : 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
      "label : 0\n",
      "\n",
      "id : 6483659\n",
      "document : 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\n",
      "label : 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 위의 5개 데이터 확인하기\n",
    "for i in range(5):\n",
    "    for col in train_dataset.column_names:\n",
    "        print(col, \":\", train_dataset[col][i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리뷰 문장의 길이 분포 그래프 그리기\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_lengths = np.array(list(map(len, train_dataset['document'])))\n",
    "\n",
    "lengths, counts = np.unique(train_lengths, return_counts=True)\n",
    "plt.bar(x=lengths, y=counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae7a0d",
   "metadata": {},
   "source": [
    "# 모델, 토크나이저 불러오기\n",
    "- [klue/bert-base](https://huggingface.co/klue/bert-base)\n",
    "    - KLUE 데이터셋을 pre-train한 BERT 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb18790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model과 tokenizer 불러오기\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"klue/bert-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ade1d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'>\n",
      "tokenizer: <class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>\n"
     ]
    }
   ],
   "source": [
    "# 불러온 model과 tokenizer 확인하기\n",
    "print('model:', model.__class__)\n",
    "print('tokenizer:', tokenizer.__class__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870eb883",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "- tokenizer로 추가되는 columns\n",
    "    - input_ids\n",
    "        - List(int), 정수로 표현된 토큰 리스트\n",
    "    - attention_mask\n",
    "        - List(int), 어텐션을 진행할 토큰 마스크\n",
    "        - 문장 토큰과 패딩 토큰을 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ce2b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 토큰화하는 함수\n",
    "def transform(data):\n",
    "    return tokenizer(\n",
    "        data['document'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c27870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 1376, 831, 2604, 18, 18, 4229, 9801, 2075, 2203, 2182, 4243, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'input_ids': [2, 1963, 18, 18, 18, 11811, 2178, 2088, 28883, 16516, 2776, 18, 18, 18, 18, 10737, 2156, 2015, 2446, 2232, 6758, 2118, 1380, 6074, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'input_ids': [2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'input_ids': [2, 12381, 3758, 2251, 2615, 18, 18, 7946, 4697, 2259, 1415, 2062, 18, 18, 20609, 4221, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'input_ids': [2, 3734, 2582, 2743, 2029, 2079, 26268, 2255, 2957, 4483, 2116, 21486, 2414, 3771, 5, 29493, 27135, 795, 15882, 2052, 2015, 2154, 1902, 2414, 21898, 3113, 28470, 2265, 2116, 5699, 2119, 21690, 2178, 2507, 2062, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# transform 데이터 테스트\n",
    "for i in range(5):\n",
    "    tokens = transform(train_dataset[i])\n",
    "    print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a31a5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-5593c927741c5627.arrow\n",
      "Loading cached processed dataset at /aiffel/.cache/huggingface/datasets/nsmc/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-7c8a59eb7687747e.arrow\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 토큰화\n",
    "train_dataset = train_dataset.map(transform, batched=True)\n",
    "test_dataset = test_dataset.map(transform, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7d2dde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'document', 'id', 'input_ids', 'label'],\n",
       "    num_rows: 150000\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리된 데이터셋 확인\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f23008",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d595d0a6",
   "metadata": {},
   "source": [
    "## Bucketing, Dynamic Padding 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f7079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "output_dir = os.getenv('HOME') + '/aiffel/transformers'\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir,\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9ed7c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_find_unused_parameters=None,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=IntervalStrategy.EPOCH,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "hub_model_id=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=2e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=-1,\n",
       "log_level=-1,\n",
       "log_level_replica=-1,\n",
       "log_on_each_node=True,\n",
       "logging_dir=/aiffel/aiffel/transformers/runs/Sep15_02-37-26_wy73nz14myc73iartlx33j2ur-54bdb8549d-sgkzf,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=1,\n",
       "output_dir=/aiffel/aiffel/transformers,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=4,\n",
       "per_device_train_batch_size=4,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard'],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=/aiffel/aiffel/transformers,\n",
       "save_on_each_node=False,\n",
       "save_steps=500,\n",
       "save_strategy=IntervalStrategy.STEPS,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_legacy_prediction_loop=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0560e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "metric = datasets.load_metric('accuracy')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc222c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b77d3cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running training *****\n",
      "  Num examples = 150000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 37500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37500' max='37500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37500/37500 4:44:00, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.395100</td>\n",
       "      <td>0.389570</td>\n",
       "      <td>0.901040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-12500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-12500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-12500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-13000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-13000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-13000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-13500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-13500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-13500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-14000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-14000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-14000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-14500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-14500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-14500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-15000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-15000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-15000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-15500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-15500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-15500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-16000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-16000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-16000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-16500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-16500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-16500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-17000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-17000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-17000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-17500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-17500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-17500/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-18500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-18500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-18500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-19000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-19000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-19000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-19500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-19500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-19500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-20000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-20000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-20000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-20500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-20500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-20500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-21500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-21500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-21500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-22000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-22000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-22000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-22500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-22500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-22500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-23000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-23000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-23000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-23500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-23500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-23500/pytorch_model.bin\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-24000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-24500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-24500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-24500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-25000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-25000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-25000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-25500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-25500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-25500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-26000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-26000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-26000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-26500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-26500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-26500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-27000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-27000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-27000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-27500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-27500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-27500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-28000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-28000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-28000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-28500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-28500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-28500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-29000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-29000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-29000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-29500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-29500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-29500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-30000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-30000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-30000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-30500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-30500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-30500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-31000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-31000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-31000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-31500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-31500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-31500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-32000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-32000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-32000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-32500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-32500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-32500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-33500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-33500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-33500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-34000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-34000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-34000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-34500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-34500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-34500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-35000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-35000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-35000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-35500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-35500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-35500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-36000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-36000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-36000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-36500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-36500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-36500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-37000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-37000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-37000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-37500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-37500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-37500/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 4\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=37500, training_loss=0.4177820764160156, metrics={'train_runtime': 17041.4261, 'train_samples_per_second': 8.802, 'train_steps_per_second': 2.201, 'total_flos': 3.9466658304e+16, 'train_loss': 0.4177820764160156, 'epoch': 1.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed2a9504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12500' max='12500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12500/12500 28:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3895704746246338,\n",
       " 'eval_accuracy': 0.90104,\n",
       " 'eval_runtime': 1686.288,\n",
       " 'eval_samples_per_second': 29.651,\n",
       " 'eval_steps_per_second': 7.413,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d80c29c",
   "metadata": {},
   "source": [
    "## Bucketing, Dynamic Padding 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리시 패딩 미적용\n",
    "def transform_without_padding(data):\n",
    "    return tokenizer(\n",
    "        data['document'],\n",
    "        truncation=True,\n",
    "        return_token_type_ids=False,\n",
    "    )\n",
    "\n",
    "# 패딩 없는 데이터셋 생성\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "train_dataset = train_dataset.map(transform_without_padding, batched=True)\n",
    "test_dataset = test_dataset.map(transform_without_padding, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "867b1cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84e3101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/klue/bert-base/resolve/main/config.json from cache at /aiffel/.cache/huggingface/transformers/fbd0b2ef898c4653902683fea8cc0dd99bf43f0e082645b913cda3b92429d1bb.99b3298ed554f2ad731c27cdb11a6215f39b90bc845ff5ce709bb4e74ba45621\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/klue/bert-base/resolve/main/pytorch_model.bin from cache at /aiffel/.cache/huggingface/transformers/05b36ee62545d769939a7746eca739b844a40a7a7553700f110b58b28ed6a949.7cb231256a5dbe886e12b902d05cb1241f330d8c19428508f91b2b28c1cfe0b6\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b366bd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir,\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    #per_device_train_batch_size=4,\n",
    "    #per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    group_by_length=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc33cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: id, document.\n",
      "***** Running training *****\n",
      "  Num examples = 150000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18750\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12408' max='18750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12408/18750 2:45:15 < 1:24:28, 1.25 it/s, Epoch 0.66/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-3500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-3500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-4500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-4500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-5500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-5500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-6500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-6500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-7500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-7500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-8500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-8500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-9500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-9500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-10500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-10500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-11500\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-11500/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/transformers/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/transformers/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/transformers/checkpoint-12000/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
