{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b915b077",
   "metadata": {},
   "source": [
    "# 1. 모델과 토크나이저 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9b552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook is running on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "# 사용하는 연산장치 확인\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"This notebook is running on\", device)\n",
    "\n",
    "# huggingface를 통해 모델과 토크나이저 불러오기\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4c435",
   "metadata": {},
   "source": [
    "## 토크나이저 확인하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6870167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': 1024,\n",
       " 'gpt2-medium': 1024,\n",
       " 'gpt2-large': 1024,\n",
       " 'gpt2-xl': 1024,\n",
       " 'distilgpt2': 1024}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 파라미터 크기별 사용하는 토큰 수 확인하기\n",
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d436d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 문장\n",
    "input_txt = \"바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f3155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 토큰화\n",
    "tokens = tokenizer(input_txt).tokens()\n",
    "\n",
    "# 토큰 정수화\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b741a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kogpt-2_tokens</th>\n",
       "      <td>▁바람</td>\n",
       "      <td>도</td>\n",
       "      <td>▁없는</td>\n",
       "      <td>▁공중에</td>\n",
       "      <td>▁수직</td>\n",
       "      <td>의</td>\n",
       "      <td>▁파</td>\n",
       "      <td>문을</td>\n",
       "      <td>▁내</td>\n",
       "      <td>이며</td>\n",
       "      <td>▁고</td>\n",
       "      <td>요</td>\n",
       "      <td>히</td>\n",
       "      <td>▁떨어지는</td>\n",
       "      <td>▁오동</td>\n",
       "      <td>잎은</td>\n",
       "      <td>▁누</td>\n",
       "      <td>구의</td>\n",
       "      <td>▁발자</td>\n",
       "      <td>취</td>\n",
       "      <td>▁입</td>\n",
       "      <td>니까</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input_IDs</th>\n",
       "      <td>10891</td>\n",
       "      <td>7235</td>\n",
       "      <td>9712</td>\n",
       "      <td>49207</td>\n",
       "      <td>14438</td>\n",
       "      <td>8143</td>\n",
       "      <td>9203</td>\n",
       "      <td>9941</td>\n",
       "      <td>9094</td>\n",
       "      <td>9639</td>\n",
       "      <td>9065</td>\n",
       "      <td>8084</td>\n",
       "      <td>8811</td>\n",
       "      <td>21215</td>\n",
       "      <td>34769</td>\n",
       "      <td>19985</td>\n",
       "      <td>9669</td>\n",
       "      <td>10139</td>\n",
       "      <td>21626</td>\n",
       "      <td>8408</td>\n",
       "      <td>9241</td>\n",
       "      <td>23775</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0     1     2      3      4     5     6     7     8     9   \\\n",
       "kogpt-2_tokens    ▁바람     도   ▁없는   ▁공중에    ▁수직     의    ▁파    문을    ▁내    이며   \n",
       "Input_IDs       10891  7235  9712  49207  14438  8143  9203  9941  9094  9639   \n",
       "\n",
       "                  10    11    12     13     14     15    16     17     18  \\\n",
       "kogpt-2_tokens    ▁고     요     히  ▁떨어지는    ▁오동     잎은    ▁누     구의    ▁발자   \n",
       "Input_IDs       9065  8084  8811  21215  34769  19985  9669  10139  21626   \n",
       "\n",
       "                  19    20     21   22  \n",
       "kogpt-2_tokens     취    ▁입     니까    .  \n",
       "Input_IDs       8408  9241  23775  389  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토큰과 해당하는 정수값 매칭을 DataFrame으로 보여주기\n",
    "pd.options.display.max_columns = 40\n",
    "pd.options.display.max_rows = 60\n",
    "df = pd.DataFrame([tokens, input_ids[0]], index=[\"kogpt-2_tokens\", \"Input_IDs\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cdfb33",
   "metadata": {},
   "source": [
    "## 모델 디코딩 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eebf305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.\" \"도대체 누가 너의 발목을 잡아넣었는지 샅샅이 수색해서 밝혀내야 할 것이네.\"\n",
      "\"정확한 것은 네게 알려주마.\"\n",
      "\"허허, 그건. 어서 빨리 말해봐야지. 왜 그러냐고 묻기라도 하면 자네만 가만 안 둘 거라구. 알았어. 네가 내 말을 듣고 무슨 짓을 한 것인지는 모르지만, 내가 말하기 전에 말이야. \"그럼, 이게 무슨 소리야?\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예제 문장 토큰화\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "# Beam Search Decoding\n",
    "max_length = 128\n",
    "output_beam = model.generate(input_ids, # 입력 시퀀스\n",
    "                             max_length=max_length, # 생성 시퀀스 최대 길이\n",
    "                             num_beams=7, # Beam Search할 범위\n",
    "                             no_repeat_ngram_size=2, # 지정된 ngram 단위로 중복 체크\n",
    "                             do_sample=True, # 토큰 샘플링\n",
    "                             temperature=2.0, # 토큰 결정시 확률 반영도\n",
    "                             top_k=50, # 후보 토큰 고를시 높은 확률순 k위까지만 보고 결정\n",
    "                            )\n",
    "\n",
    "# beam search로 만들어진 문장중 하나 출력\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53ed08",
   "metadata": {},
   "source": [
    "# 2. 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c21973",
   "metadata": {},
   "source": [
    "## SFT(Supervised Fine-Tuning) 데이터셋 \n",
    "- prompt\n",
    "    - 사용자가 올릴 질문\n",
    "- completion\n",
    "    - 모델이 생성해야할 답변\n",
    "- tokens\n",
    "    - 총 토큰 수로 추정\n",
    "    - KoChatGPT가 학습할 때 사용할 tokenizer 기준으로 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf0b1968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT 데이터셋 크기: 12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '불고기용 고기 한우에요?',\n",
       "  'completion': \"'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\",\n",
       "  'tokens': 193},\n",
       " {'prompt': '쓰던 앱이 유료로 전환됐어',\n",
       "  'completion': \"'어떤 앱인지 모르기 때문에 정확한 답변을 드리기 어렵습니다. 하지만, 일반적으로 유료 전환된 앱은 기존 무료 앱에서 추가적인 기능이나 서비스를 제공하는 경우가 많습니다. 이 경우, 유료 전환 이전 가격이 매우 저렴하거나 무료인 경우가 많으므로, 앱을 계속 사용하려면 추가적인 비용을 지불해야 할 수 있습니다. 하지만, 유료 전환 이후에는 기존 사용자 또는 새로운 사용자 모두가 추가 기능과 높은 품질의 서비스를 이용할 수 있게 됩니다. 따라서, 앱 개발자는 유료 모델로 전환함으로써 앱의 수익을 증가시키고 더 나은 서비스를 제공할 수 있습니다.\",\n",
       "  'tokens': 288},\n",
       " {'prompt': '여친이랑 다툼',\n",
       "  'completion': \"'저는 인공지능이기 때문에 여친과의 다툼에 대해서는 조언을 드릴 수는 없습니다. 하지만 다투게 되면 상대방의 말을 경청하는 태도와 서로의 감정을 존중하는 것이 중요합니다. 논리적이고 차분한 대화를 통해 문제를 해결해보세요. 그리고 서로를 이해하고 서로의 의견을 수용하는 것이 중요합니다.\",\n",
       "  'tokens': 153}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "\n",
    "HOME_DIR = os.getenv('HOME')\n",
    "\n",
    "data_path_1_SFT = HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl' \n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "# SFT 데이터셋 크기\n",
    "print('SFT 데이터셋 크기:', len(list_data_dict))\n",
    "\n",
    "# SFT 데이터셋 확인하기\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02e8a6",
   "metadata": {},
   "source": [
    "## RM (Reward Model) 데이터셋\n",
    "- prompt\n",
    "    - 사용자가 올릴 질문\n",
    "- completion_0, completion_1, completion_2\n",
    "    - 각 모델별 답변\n",
    "        - ChatGPT\n",
    "        - GPT3(Ada)\n",
    "        - GPT3(Davinci)\n",
    "    - 어떤 답변이 어떤 모델로 생성됐는지 알수 없도록 답변 순서를 섞음\n",
    "- ranking\n",
    "    - 사람이 라벨링한 각 답변의 품질 랭킹\n",
    "    - 값이 낮을수록 높은 품질"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "974b4e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RM 데이터셋 크기: 10220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?',\n",
       "  'completion_0': 'Allow me to answer your question. I know that you are curious about me.',\n",
       "  'completion_1': '번디는 다양한 인터뷰자들과 뉴스홍보 담당자들과의 면담 때 밝혔다.',\n",
       "  'completion_2': '라이언에게 말했다.',\n",
       "  'ranking': [2, 1, 0]},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?',\n",
       "  'completion_0': '개포주공아파트는 다섯 단지로 이루어져 있습니다.',\n",
       "  'completion_1': '이날 목송에서 구글상위노',\n",
       "  'completion_2': '개포주공아파트는 총 27개 단지로 이루어져 있습니다.',\n",
       "  'ranking': [2, 0, 1]},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?',\n",
       "  'completion_0': 'The diameter of the Metallic domain is bigger than the Hyperonic domain.',\n",
       "  'completion_1': '이 질문은 조금 불분명합니다. 김영삼 대통령이 후보 시절에 어떤 발언을 했고, 누가 그 발언을 문제삼았는지에 따라 답이 다를 수 있습니다.\\\\n\\\\n만약 김영삼 대통령이 후보 시절에 지역표심을 겨냥한 발언을 했다는 가정하에, 그 발언을 문제삼은 후보가 누구였는지를 대답하자면, 그 답은 이화선 당시 민주당 대통령 후보가 될 것입니다. 1992년 총선 때, 김영삼 대선후보는 \"집값이 오른 노량진역 부근의 부동산 가격은 세월호 폭침 후 \\\\\\'강남 도시재생\\\\\\' 일환으로 상승했다\"는 발언을 했습니다. 하지만 이화선 후보는 이 발언을 \"전국적으로 경제적 발전이 이루어지지 않은 지방민의 마음을 멀리해지려는 무례한 발언\"이라고 비판하며 문제삼았습니다.\\\\n\\\\n하지만, 이 질문을 답변하는 데 있어서 보다 명확한 정보가 있으면 답변을 보완할 수 있습니다.',\n",
       "  'completion_2': '김영삼의 후보 시절에 지역표심을 겨냥한 발언은 대통령 당선 전까지 대한민국 정부가 추구하고 있는 민주주의 광범위하게 확립과 보수의 사상을 이어가는 데 있어 지역경제 발전과 공공서비스 신속 개선을 위해 합리적인 국가 정책에 따르는 방향성을 제시하고 있습니다.',\n",
       "  'ranking': [1, 2, 0]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_2_RM = HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "with open(data_path_2_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "# RM 데이터셋 크기\n",
    "print(\"RM 데이터셋 크기:\", len(list_data_dict))\n",
    "\n",
    "# RM 데이터셋 확인하기\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fb17c2",
   "metadata": {},
   "source": [
    "## PPO 데이터셋\n",
    "- prompt\n",
    "    - 사용자가 전달할 질문\n",
    "    - SFT한 모델이 답변을 생성하고 RM이 주는 reward에 따라 학습하기 때문에 prompt밖에 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37773fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO 데이터셋 크기: 12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?'},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_3_PPO = HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "# PPO 데이터셋 크기\n",
    "print(\"PPO 데이터셋 크기:\", len(list_data_dict))\n",
    "\n",
    "# PPO 데이터셋 확인하기\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d18c1",
   "metadata": {},
   "source": [
    "# 3. Supervised Fine-Tuning\n",
    "- Foundation 모델이 일단 원하는 Downstream Task를 해결할 수 있도록 Fine-Tuning\n",
    "    - ![SFT](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/rlhf/pretraining.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fec9ad15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713196a3",
   "metadata": {},
   "source": [
    "## STF를 수행할 모델과 토크나이저 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85ff38fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', # 토크나이저를 가져올 모델\n",
    "                                          bos_token='</s>',     # 시작 토큰\n",
    "                                          eos_token='</s>',     # 종료 토큰\n",
    "                                          unk_token='</s>',     # OOV 토큰\n",
    "                                          pad_token='</s>',     # 패딩 토큰\n",
    "                                          padding_side=\"right\", # 패딩 방향\n",
    "                                          model_max_length=512, # 입력 문장 최대 길이\n",
    "                                         )\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932b3e8",
   "metadata": {},
   "source": [
    "## STF 데이터셋 클래스 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5decbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "\n",
    "class SFT_dataset(Dataset): # Pytorch Dataset 클래스\n",
    "    def __init__(self, \n",
    "                 data_path_1_SFT: str, # SFT 데이터가 들어있는 파일 위치\n",
    "                 tokenizer: transformers.PreTrainedTokenizer, # 토크나이저\n",
    "                 verbose=False,\n",
    "                ):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        # 질문 문장과 대답 문장 column 이름\n",
    "        pattern_instruction = 'prompt' # 원본 질문 문장\n",
    "        pattern_output = 'completion' # 원본 대답 문장\n",
    "\n",
    "        # json 데이터셋 파일 불러오기\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        # 지시문 정의\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        # 질문 문장 전처리\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example) # 지시문 추가\n",
    "            sources.append(tmp)\n",
    "\n",
    "        # 대답 문장 전처리\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\") # 종료 토큰 추가\n",
    "        examples = [s + t for s, t in zip(sources, targets)] # 질문 문장과 대답 문장 연결\n",
    "\n",
    "        # 문장 토큰화\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # 질문\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # 질문 + 대답\n",
    "\n",
    "        # 시퀀스 정수화\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100 # 질문 + 대답 시퀀스에서 질문 부분에 마스킹\n",
    "                                      # Pytorch에서 마스크 값이 -100로 지정되어 있음\n",
    "\n",
    "        # 데이터셋 생성\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, \n",
    "                     strings: Sequence[str], # 토큰화할 문장 리스트\n",
    "                     tokenizer: transformers.PreTrainedTokenizer, # 토크나이저\n",
    "                    ) -> Dict:\n",
    "        \"\"\"\n",
    "        문장을 토큰화해 시퀀스 정보를 딕셔너리에 담아 변환\n",
    "        \"\"\"\n",
    "        # 문장 토큰화\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        \n",
    "        # 정수 시퀀스\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        \n",
    "        # 시퀀스 길이\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() # pad_token이 아닌 토큰 개수\n",
    "            for tokenized in tokenized_list\n",
    "        ]\n",
    "        \n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        데이터셋 크기 반환\n",
    "        \"\"\"\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        데이터셋의 샘플 반환\n",
    "        \"\"\"\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ae85197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 모델이 학습할 수 있도록 SFT 데이터셋에 attention mask 추가\n",
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        \n",
    "        # input_ids와 labels 패딩 추가\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id), # 어텐션 마스크, 패딩 토큰 제외\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "198d8b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([  739,   378,   378,   378, 14659, 13394, 37091, 10651,   383, 25841,\n",
      "         8006, 14914,   375,  7673, 20479,  8091, 22311,  9036, 30902, 13675,\n",
      "          375,   378,   378,   378, 41951,   454,  9549, 20549,   383,  8142,\n",
      "         7192, 14914,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n",
      "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n"
     ]
    }
   ],
   "source": [
    "SFT_DATASET_PATH = HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl'\n",
    "\n",
    "train_dataset = SFT_dataset(data_path_1_SFT=SFT_DATASET_PATH, tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "# 최종 데이터셋의 샘플 확인\n",
    "print('input : %s'%train_dataset.input_ids[0])\n",
    "print('output: %s'%train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3abc5b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.</s>\n",
      "\n",
      "\n",
      "\n",
      "labels:\n",
      "' 저는 인공 지 능  챗 봇 이며, 직접적으로 식품 에 관한 정보를 가지고 있지 않 습니다. 하지만 일반적으로 불 고기 용 고 기는 한 우, 쇠고 기, 돼지고 기 등 다양한 종류의 고기를 사용 합니다. 하지만 한 우는 대표적인 고급 육 류로 알려져 있기 때문에, 한 우를 사용하는 경우도 많 습니다. 알 러 지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택 해 주 시기 바 랍 니다. </s> \n"
     ]
    }
   ],
   "source": [
    "# 디코딩 후 확인\n",
    "print('input_ids:')\n",
    "print(tokenizer.decode(train_dataset.input_ids[0]))\n",
    "print('\\n\\n')\n",
    "\n",
    "print('labels:')\n",
    "for token in train_dataset.labels[0]:\n",
    "    if token != -100:\n",
    "        print(tokenizer.decode(token), end=' ')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f996d",
   "metadata": {},
   "source": [
    "## SFT Trainer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b8ffd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"aiffel/KoChatGPT/test\", # checkpoint를 저장할 위치\n",
    "    overwrite_output_dir=True, # 덮어쓰기 허용\n",
    "    num_train_epochs=1, # 학습 epoch 수\n",
    "    per_device_train_batch_size=8, # 연산 장치당 학습 배치 크기\n",
    "    per_device_eval_batch_size=8, # 연산 장치당 평가 배치 크기\n",
    "    warmup_steps=5, # warmup steps, 학습 시작시 0부터 learning_rate까지 천천히 높이는 step 수\n",
    "    prediction_loss_only=True, # loss값만 반환\n",
    "    fp16 = True # 가중치는 fp16 타입 사용\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b58387c",
   "metadata": {},
   "source": [
    "## SFT 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f30657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 06:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.984100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.687200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('aiffel/KoChatGPT/output_1_SFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07a50a",
   "metadata": {},
   "source": [
    "## SFT 결과 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "813ef53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 어시스턴트이기 때문에 불고기용 고기의 종류와 양에 대한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기는 쇠고기와 함께 먹는 음식 중 하나입니다. 따라서 불고기를 먹을 수 있는 종류는 다양합니다. 예를 들어, 닭가슴살 스테이크, 오므라이스 샐러드 등이 있습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨은 42대 부통령직을 수행했습니다.作)作)은 \"리처드 닉슨\"이 41대 부통령을 수행한 년도를 가리키는 말입니다.作)는 \"리처드 닉슨\"이 40대 부통령을 맡았던 년도를 의미합니다.作은 \"리처드슨\"이 50대 부통령\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어?\n",
      "\n",
      "### Response(응답):'시카고 오 헤어 국제공항은 미국 캘리포니아주 샌프란시스코에 위치해 있습니다.子供共和國際空港)이라고 불립니다.子供公和国際空港이라는 뜻입니다.子供空和國際公港이라는 이름을 가진 항공사는 다음과 같습니다.\\n\\n1. 대한항공\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇으로써 미세먼지 정보를 알 수 없습니다. 미세먼지 예보를 확인해 보시는 것이 좋겠습니다.\\n\\n미세먼지 예보: 일반적으로 미세먼지는 주로 중국에서 발원하여 중국 전역으로 퍼져나가기 때문에 중국발 미세먼지가 유입될\n"
     ]
    }
   ],
   "source": [
    "# 모델을 통해 문장 생성하는 pipeline\n",
    "generator = pipeline('text-generation', model='aiffel/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "# generator.__call__()에 전달할 파라미터\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# 지시문\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# 확인용 질문 문장\n",
    "list_prompt = ['불고기용 고기 한우에요?',\n",
    "               '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "               '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "               '오늘 미세먼지 어때?']\n",
    "\n",
    "# 질문 문장에 지시문 추가\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "# SFT을 진행한 모델 추론\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f177c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 모델 학습을 위해 할당한 GPU 메모리 초기화\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cda0a3b",
   "metadata": {},
   "source": [
    "# 4. Reward Model\n",
    "- 어떤 답변이 더욱 선호되는지 평가하는 모델 만들고 학습시키기\n",
    "    - ![RM](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/rlhf/reward-model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "886115d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /aiffel/aiffel/KoChatGPT/colossalai_ChatGPT_230319\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.20.1 in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (4.28.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (4.62.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (2.13.1)\n",
      "Requirement already satisfied: loralib in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (0.1.1)\n",
      "Requirement already satisfied: colossalai>=0.2.4 in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (0.2.7)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (1.12.1)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.9/site-packages (from chatgpt==0.1.0) (0.0.113)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (13.4.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (21.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (1.21.4)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (3.3.3)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (1.11.1)\n",
      "Requirement already satisfied: fabric in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (3.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (8.0.3)\n",
      "Requirement already satisfied: contexttimer in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (0.3.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from colossalai>=0.2.4->chatgpt==0.1.0) (5.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (0.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (0.15.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (2.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers>=4.20.1->chatgpt==0.1.0) (3.12.2)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (0.3.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (2.0.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (1.3.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (2021.11.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (3.8.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (12.0.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets->chatgpt==0.1.0) (0.70.12.2)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /opt/conda/lib/python3.9/site-packages (from langchain->chatgpt==0.1.0) (1.4.48)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.9/site-packages (from langchain->chatgpt==0.1.0) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/conda/lib/python3.9/site-packages (from langchain->chatgpt==0.1.0) (0.5.8)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /opt/conda/lib/python3.9/site-packages (from langchain->chatgpt==0.1.0) (1.10.9)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.9/site-packages (from torch->chatgpt==0.1.0) (4.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (2.0.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets->chatgpt==0.1.0) (4.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/conda/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/conda/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->colossalai>=0.2.4->chatgpt==0.1.0) (3.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers>=4.20.1->chatgpt==0.1.0) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.9/site-packages (from SQLAlchemy<2,>=1->langchain->chatgpt==0.1.0) (2.0.2)\n",
      "Requirement already satisfied: invoke>=2.0 in /opt/conda/lib/python3.9/site-packages (from fabric->colossalai>=0.2.4->chatgpt==0.1.0) (2.1.3)\n",
      "Requirement already satisfied: paramiko>=2.4 in /opt/conda/lib/python3.9/site-packages (from fabric->colossalai>=0.2.4->chatgpt==0.1.0) (3.2.0)\n",
      "Requirement already satisfied: decorator>=5 in /opt/conda/lib/python3.9/site-packages (from fabric->colossalai>=0.2.4->chatgpt==0.1.0) (5.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->chatgpt==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets->chatgpt==0.1.0) (2021.3)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (2.5.24)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (1.8.0)\n",
      "Requirement already satisfied: virtualenv>=20.10.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (20.23.1)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (3.3.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from rich->colossalai>=0.2.4->chatgpt==0.1.0) (2.15.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.9/site-packages (from rich->colossalai>=0.2.4->chatgpt==0.1.0) (3.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->colossalai>=0.2.4->chatgpt==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from nodeenv>=0.11.1->pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (59.4.0)\n",
      "Requirement already satisfied: cryptography>=3.3 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (41.0.1)\n",
      "Requirement already satisfied: bcrypt>=3.2 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (4.0.1)\n",
      "Requirement already satisfied: pynacl>=1.5 in /opt/conda/lib/python3.9/site-packages (from paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets->chatgpt==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain->chatgpt==0.1.0) (0.4.3)\n",
      "Requirement already satisfied: platformdirs<4,>=3.5.1 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (3.8.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.9/site-packages (from virtualenv>=20.10.0->pre-commit->colossalai>=0.2.4->chatgpt==0.1.0) (0.3.6)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.9/site-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai>=0.2.4->chatgpt==0.1.0) (2.21)\n",
      "Building wheels for collected packages: chatgpt\n",
      "  Building wheel for chatgpt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chatgpt: filename=chatgpt-0.1.0-py3-none-any.whl size=46664 sha256=e01a4b16d46a3b25be1dca74747760c4fa0430beaea224f672953f80884b1548\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ohr49ub2/wheels/79/25/c3/338e0c56a2253a8ea6c41e8692f6eb2409a3898c63b234b103\n",
      "Successfully built chatgpt\n",
      "Installing collected packages: chatgpt\n",
      "  Attempting uninstall: chatgpt\n",
      "    Found existing installation: chatgpt 0.1.0\n",
      "    Uninstalling chatgpt-0.1.0:\n",
      "      Successfully uninstalled chatgpt-0.1.0\n",
      "Successfully installed chatgpt-0.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"$HOME/aiffel/KoChatGPT/colossalai_ChatGPT_230319/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd9b0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85007692",
   "metadata": {},
   "source": [
    "## RM 모델 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c71aec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None, # pre-trained 모델\n",
    "                 config: Optional[GPT2Config] = None, # pre-trained 모델 설정\n",
    "                 checkpoint: bool = False, # 체크포인트 저장\n",
    "                 lora_rank: int = 0, # 학습에 lora 적용시 rank 수\n",
    "                 lora_train_bias: str = 'none', # lora 및 pre-trained 모델의 bias 학습 적용 여부\n",
    "                 tokenizer=None # 토크나이저\n",
    "                ) -> None:\n",
    "        # 모델 불러오기\n",
    "        if pretrained is not None: \n",
    "            # 지정된 pre-trained 모델 불러오기\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None: \n",
    "            # 지정된 config 적용해 GPT2 모델 생성\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            # 기본 설정으로 GPT2 모델 생성\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            # checkpoint 불러오기\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        # reward가 스칼라값으로 나오도록 Head 설정\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        # 모델 멤버 변수에 저장\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        \"\"\"\n",
    "        학습한 Reward Model 가중치 저장하기\n",
    "        \"\"\"\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eafda61",
   "metadata": {},
   "source": [
    "## RM 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cdfb528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "# RM 불러오기\n",
    "with NaiveStrategy().model_init_context(): # Single GPU 환경\n",
    "        model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0325a6",
   "metadata": {},
   "source": [
    "## RM 데이테셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ac88280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': '애플은 리사를 어떻게 처리했어', 'chosen': '애플이 누구인지 명확히 알 수 없어서, 리사가 누구인지와 어떤 상황에서 처리되었는지에 대한 추가적인 정보가 필요합니다. 따라서, 보다 정확한 답변을 제공할 수 없습니다.', 'rejected': '애플은 리사를 위해 고객 서비스 부서에서 고객 다양한 컴퓨터 관련 문제에 대해 응답하는 데 필요한 모든 지원을 제공했습니다. 사용자가 하드웨어 문제를 경험할 때, 전문가들은 필요한 수리(수리, 추가 부품 제공, 소프트웨어 업그레이드 등)을 제공해 드릴 수 있습니다. 또한, 사용자가 사용 방법 문제나 기타 문제를 경험할 때, 대화 상대로 사용자를 지원할 수 있는 전문 고객 서비스 직원들이 사용자에게 상담하고 도움을 주는 데 도움이 될 수 있는 정보를 제공합니다. 또한, 인터넷에서 제공되는 정보를 통해 문제를 해결하거나 고객 서비스 웹 사이트를 통해 자신의 문제를 진단할 수 있도록 하는 등 다양한 방법으로 리사를 처리해 왔습니다.'}\n"
     ]
    }
   ],
   "source": [
    "with open(HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    # 둘 중 랭킹이 높은 (값이 낮은) 답변을 chosen으로 저장\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    # 이하 동문\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    # 이하 동문\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "# RM 데이터셋 가공 전 크기\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "# RM 데이터셋 가공 후 크기\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "# RM 데이터셋 가공된 샘플\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf55add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은?', 'chosen': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은 류승완의 사무실입니다.', 'rejected': '대구 영화사옥'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(230319)\n",
    "\n",
    "# 데이터셋 순서 섞기\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcd5988b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 870.78it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 1010.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "# train/test 데이터셋 크기\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "# RewardDataset으로 Wrapping\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8093c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "## prompt ##\n",
      "흑고래의 무게는 어느 정도야\n",
      "######################################################################\n",
      "## chosen ##\n",
      "흑고래의 평균 몸무게는 약 25~40톤 정도이지만, 최대 몸무게는 50톤 이상에 이를 수 있습니다.\n",
      "######################################################################\n",
      "## rejected ##\n",
      "흑고래의 무게는 매우 다양하게 달라집니다. 약 200kg에서 10톤까지 달라질 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# RewardDataset 확인하기 \n",
    "idx = 1\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f17c60a",
   "metadata": {},
   "source": [
    "## RM Trainer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cfa873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d97b4bf",
   "metadata": {},
   "source": [
    "## RM 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd752ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Train step of epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:00<03:44,  1.11it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:00<03:44,  1.11it/s, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:01<03:37,  1.14it/s, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:01<03:37,  1.14it/s, loss=0.751]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:34,  1.15it/s, loss=0.751]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:34,  1.15it/s, loss=0.534]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:32,  1.16it/s, loss=0.534]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:32,  1.16it/s, loss=0.476]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:31,  1.16it/s, loss=0.476]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:31,  1.16it/s, loss=0.448]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:30,  1.16it/s, loss=0.448]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:30,  1.16it/s, loss=1.22] \u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:29,  1.16it/s, loss=1.22]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:29,  1.16it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:06<03:28,  1.16it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:06<03:28,  1.16it/s, loss=1.44] \u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:07<03:28,  1.16it/s, loss=1.44]\u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:07<03:28,  1.16it/s, loss=0.419]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:08<03:27,  1.16it/s, loss=0.419]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:08<03:27,  1.16it/s, loss=0.508]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:09<03:26,  1.16it/s, loss=0.508]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:09<03:26,  1.16it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:10<03:25,  1.16it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:10<03:25,  1.16it/s, loss=0.399]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:11<03:25,  1.16it/s, loss=0.399]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:11<03:25,  1.16it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:24,  1.15it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:24,  1.15it/s, loss=1.1]  \u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:12<03:23,  1.15it/s, loss=1.1]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:13<03:23,  1.15it/s, loss=0.567]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:13<03:23,  1.15it/s, loss=0.567]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:13<03:23,  1.15it/s, loss=1.34] \u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:14<03:22,  1.15it/s, loss=1.34]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:14<03:22,  1.15it/s, loss=0.703]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:15<03:21,  1.15it/s, loss=0.703]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:15<03:21,  1.15it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:16<03:21,  1.15it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:16<03:21,  1.15it/s, loss=0.662]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:17<03:20,  1.15it/s, loss=0.662]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:17<03:20,  1.15it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:18<03:19,  1.15it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:18<03:19,  1.15it/s, loss=0.653]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:19<03:18,  1.15it/s, loss=0.653]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:19<03:18,  1.15it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:19<03:18,  1.15it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:19<03:18,  1.15it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:20<03:17,  1.15it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:20<03:17,  1.15it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:21<03:16,  1.14it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:21<03:16,  1.14it/s, loss=0.623]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:22<03:16,  1.14it/s, loss=0.623]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:22<03:16,  1.14it/s, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:23<03:15,  1.14it/s, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:23<03:15,  1.14it/s, loss=0.615]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:24<03:14,  1.14it/s, loss=0.615]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:24<03:14,  1.14it/s, loss=0.576]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:25<03:13,  1.14it/s, loss=0.576]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:25<03:13,  1.14it/s, loss=0.482]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:26<03:13,  1.14it/s, loss=0.482]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:26<03:13,  1.14it/s, loss=0.578]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:26<03:12,  1.14it/s, loss=0.578]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:27<03:12,  1.14it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:27<03:11,  1.14it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:27<03:11,  1.14it/s, loss=0.865]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:28<03:11,  1.14it/s, loss=0.865]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:28<03:11,  1.14it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:29<03:10,  1.13it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:29<03:10,  1.13it/s, loss=0.452]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:30<03:09,  1.13it/s, loss=0.452]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:30<03:09,  1.13it/s, loss=0.824]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:31<03:08,  1.13it/s, loss=0.824]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:31<03:08,  1.13it/s, loss=1.11] \u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:32<03:07,  1.13it/s, loss=1.11]\u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:32<03:07,  1.13it/s, loss=0.848]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:33<03:07,  1.13it/s, loss=0.848]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:33<03:07,  1.13it/s, loss=0.458]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:34<03:06,  1.13it/s, loss=0.458]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:34<03:06,  1.13it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:34<03:05,  1.13it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:34<03:05,  1.13it/s, loss=0.395]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:35<03:04,  1.13it/s, loss=0.395]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:35<03:04,  1.13it/s, loss=0.423]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:36<03:04,  1.13it/s, loss=0.423]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:36<03:04,  1.13it/s, loss=0.646]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:37<03:03,  1.13it/s, loss=0.646]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:37<03:03,  1.13it/s, loss=0.781]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:38<03:02,  1.13it/s, loss=0.781]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:38<03:02,  1.13it/s, loss=0.987]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:39<03:01,  1.13it/s, loss=0.987]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:39<03:01,  1.13it/s, loss=0.61] \u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:40<03:00,  1.13it/s, loss=0.61]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:40<03:00,  1.13it/s, loss=0.437]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:41<02:59,  1.13it/s, loss=0.437]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:41<02:59,  1.13it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:42<02:59,  1.13it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:42<02:59,  1.13it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:42<02:58,  1.13it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:42<02:58,  1.13it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:43<02:57,  1.12it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:43<02:57,  1.12it/s, loss=0.847]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:44<02:56,  1.13it/s, loss=0.847]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:44<02:56,  1.13it/s, loss=0.457]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:45<02:55,  1.13it/s, loss=0.457]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:45<02:55,  1.13it/s, loss=0.571]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:46<02:55,  1.12it/s, loss=0.571]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:46<02:55,  1.12it/s, loss=0.411]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:47<02:54,  1.12it/s, loss=0.411]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:47<02:54,  1.12it/s, loss=0.333]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:48<02:53,  1.12it/s, loss=0.333]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:48<02:53,  1.12it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:49<02:52,  1.12it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:49<02:52,  1.12it/s, loss=0.563]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:50<02:51,  1.12it/s, loss=0.563]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:50<02:51,  1.12it/s, loss=0.539]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:50<02:50,  1.12it/s, loss=0.539]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:50<02:50,  1.12it/s, loss=0.584]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:51<02:49,  1.12it/s, loss=0.584]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:51<02:49,  1.12it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:52<02:49,  1.12it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:52<02:49,  1.12it/s, loss=0.326]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:53<02:48,  1.12it/s, loss=0.326]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:53<02:48,  1.12it/s, loss=1.22] \u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:54<02:47,  1.12it/s, loss=1.22]\u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:54<02:47,  1.12it/s, loss=0.175]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:55<02:46,  1.13it/s, loss=0.175]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:55<02:46,  1.13it/s, loss=0.858]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:56<02:45,  1.13it/s, loss=0.858]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:56<02:45,  1.13it/s, loss=0.346]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:57<02:44,  1.13it/s, loss=0.346]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:57<02:44,  1.13it/s, loss=0.767]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:58<02:43,  1.13it/s, loss=0.767]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:58<02:43,  1.13it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [00:58<02:42,  1.13it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [00:58<02:42,  1.13it/s, loss=0.861]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [00:59<02:41,  1.13it/s, loss=0.861]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [00:59<02:41,  1.13it/s, loss=0.38] \u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:00<02:40,  1.13it/s, loss=0.38]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:00<02:40,  1.13it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:01<02:39,  1.13it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:01<02:39,  1.13it/s, loss=0.731]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:02<02:38,  1.13it/s, loss=0.731]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:02<02:38,  1.13it/s, loss=0.528]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:03<02:37,  1.13it/s, loss=0.528]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:03<02:37,  1.13it/s, loss=0.775]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:04<02:36,  1.13it/s, loss=0.775]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:04<02:36,  1.13it/s, loss=0.714]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:05<02:35,  1.13it/s, loss=0.714]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:05<02:35,  1.13it/s, loss=0.591]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:06<02:34,  1.13it/s, loss=0.591]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:06<02:34,  1.13it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:06<02:33,  1.13it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:06<02:33,  1.13it/s, loss=0.723]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:07<02:32,  1.14it/s, loss=0.723]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:07<02:32,  1.14it/s, loss=0.444]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:08<02:31,  1.14it/s, loss=0.444]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:08<02:31,  1.14it/s, loss=0.628]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:09<02:30,  1.14it/s, loss=0.628]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:09<02:30,  1.14it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:10<02:29,  1.14it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:10<02:29,  1.14it/s, loss=0.689]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:11<02:28,  1.14it/s, loss=0.689]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:11<02:28,  1.14it/s, loss=0.408]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:12<02:27,  1.14it/s, loss=0.408]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:12<02:27,  1.14it/s, loss=0.833]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:13<02:26,  1.14it/s, loss=0.833]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:13<02:26,  1.14it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:13<02:25,  1.14it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:13<02:25,  1.14it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:14<02:24,  1.14it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:14<02:24,  1.14it/s, loss=0.727]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:15<02:23,  1.14it/s, loss=0.727]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:15<02:23,  1.14it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:16<02:22,  1.14it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:16<02:22,  1.14it/s, loss=0.465]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:17<02:21,  1.14it/s, loss=0.465]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:17<02:21,  1.14it/s, loss=0.919]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:18<02:21,  1.14it/s, loss=0.919]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:18<02:21,  1.14it/s, loss=0.821]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:19<02:20,  1.14it/s, loss=0.821]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:19<02:20,  1.14it/s, loss=0.757]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:20<02:19,  1.14it/s, loss=0.757]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:20<02:19,  1.14it/s, loss=0.61] \u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:20<02:18,  1.14it/s, loss=0.61]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:20<02:18,  1.14it/s, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:21<02:17,  1.14it/s, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:21<02:17,  1.14it/s, loss=0.856]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:22<02:16,  1.14it/s, loss=0.856]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:22<02:16,  1.14it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:23<02:15,  1.14it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:23<02:15,  1.14it/s, loss=0.495]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:24<02:15,  1.14it/s, loss=0.495]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:24<02:15,  1.14it/s, loss=0.703]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:25<02:14,  1.14it/s, loss=0.703]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:25<02:14,  1.14it/s, loss=0.811]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:26<02:13,  1.14it/s, loss=0.811]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:26<02:13,  1.14it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:27<02:12,  1.14it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:27<02:12,  1.14it/s, loss=0.603]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:27<02:11,  1.14it/s, loss=0.603]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:27<02:11,  1.14it/s, loss=0.657]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:28<02:10,  1.14it/s, loss=0.657]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:28<02:10,  1.14it/s, loss=0.7]  \u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:29<02:09,  1.14it/s, loss=0.7]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:29<02:09,  1.14it/s, loss=0.684]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:30<02:08,  1.14it/s, loss=0.684]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:30<02:08,  1.14it/s, loss=0.734]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:31<02:07,  1.14it/s, loss=0.734]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:31<02:07,  1.14it/s, loss=0.765]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:32<02:07,  1.14it/s, loss=0.765]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:32<02:07,  1.14it/s, loss=0.65] \u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:33<02:06,  1.14it/s, loss=0.65]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:33<02:06,  1.14it/s, loss=0.682]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:34<02:05,  1.14it/s, loss=0.682]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:34<02:05,  1.14it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:34<02:04,  1.14it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:34<02:04,  1.14it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:35<02:03,  1.14it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:35<02:03,  1.14it/s, loss=0.66] \u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:36<02:02,  1.14it/s, loss=0.66]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:36<02:02,  1.14it/s, loss=0.757]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:37<02:01,  1.14it/s, loss=0.757]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:37<02:01,  1.14it/s, loss=0.605]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:38<02:00,  1.14it/s, loss=0.605]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:38<02:00,  1.14it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:39<02:00,  1.14it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:39<02:00,  1.14it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:40<01:59,  1.14it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:40<01:59,  1.14it/s, loss=0.829]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:41<01:58,  1.14it/s, loss=0.829]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:41<01:58,  1.14it/s, loss=0.668]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:41<01:57,  1.14it/s, loss=0.668]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:41<01:57,  1.14it/s, loss=0.588]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:42<01:56,  1.14it/s, loss=0.588]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:42<01:56,  1.14it/s, loss=0.558]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:43<01:55,  1.14it/s, loss=0.558]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:43<01:55,  1.14it/s, loss=0.502]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:44<01:54,  1.14it/s, loss=0.502]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:44<01:54,  1.14it/s, loss=0.522]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:45<01:53,  1.14it/s, loss=0.522]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:45<01:53,  1.14it/s, loss=0.997]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:46<01:53,  1.14it/s, loss=0.997]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:46<01:53,  1.14it/s, loss=0.786]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:47<01:52,  1.14it/s, loss=0.786]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:47<01:52,  1.14it/s, loss=0.662]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:48<01:51,  1.14it/s, loss=0.662]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:48<01:51,  1.14it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:48<01:50,  1.14it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:48<01:50,  1.14it/s, loss=0.747]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:49<01:49,  1.14it/s, loss=0.747]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:49<01:49,  1.14it/s, loss=0.663]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:50<01:48,  1.14it/s, loss=0.663]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:50<01:48,  1.14it/s, loss=0.698]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:51<01:48,  1.14it/s, loss=0.698]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:51<01:48,  1.14it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:52<01:47,  1.14it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:52<01:47,  1.14it/s, loss=0.627]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:53<01:46,  1.14it/s, loss=0.627]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:53<01:46,  1.14it/s, loss=0.641]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:54<01:45,  1.14it/s, loss=0.641]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:54<01:45,  1.14it/s, loss=0.571]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:55<01:44,  1.14it/s, loss=0.571]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:55<01:44,  1.14it/s, loss=0.909]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:56<01:43,  1.14it/s, loss=0.909]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:56<01:43,  1.14it/s, loss=0.597]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:56<01:43,  1.14it/s, loss=0.597]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:56<01:43,  1.14it/s, loss=0.784]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [01:57<01:42,  1.14it/s, loss=0.784]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [01:57<01:42,  1.14it/s, loss=0.73] \u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [01:58<01:41,  1.14it/s, loss=0.73]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [01:58<01:41,  1.14it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [01:59<01:40,  1.14it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [01:59<01:40,  1.14it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:00<01:39,  1.14it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:00<01:39,  1.14it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:01<01:38,  1.14it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:01<01:38,  1.14it/s, loss=0.653]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:02<01:37,  1.14it/s, loss=0.653]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:02<01:37,  1.14it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:03<01:36,  1.14it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:03<01:36,  1.14it/s, loss=0.494]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:03<01:36,  1.13it/s, loss=0.494]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:03<01:36,  1.13it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:04<01:35,  1.13it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:04<01:35,  1.13it/s, loss=0.867]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:05<01:34,  1.13it/s, loss=0.867]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:05<01:34,  1.13it/s, loss=0.551]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:06<01:33,  1.13it/s, loss=0.551]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:06<01:33,  1.13it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:07<01:32,  1.13it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:07<01:32,  1.13it/s, loss=0.655]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:08<01:31,  1.13it/s, loss=0.655]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:08<01:31,  1.13it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:09<01:30,  1.13it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:09<01:30,  1.13it/s, loss=0.383]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:10<01:30,  1.13it/s, loss=0.383]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:10<01:30,  1.13it/s, loss=0.614]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:11<01:29,  1.13it/s, loss=0.614]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:11<01:29,  1.13it/s, loss=0.667]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:11<01:28,  1.13it/s, loss=0.667]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:11<01:28,  1.13it/s, loss=0.607]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:12<01:27,  1.13it/s, loss=0.607]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:12<01:27,  1.13it/s, loss=0.222]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:13<01:26,  1.13it/s, loss=0.222]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:13<01:26,  1.13it/s, loss=0.517]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:14<01:25,  1.13it/s, loss=0.517]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:14<01:25,  1.13it/s, loss=0.596]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:15<01:24,  1.13it/s, loss=0.596]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:15<01:24,  1.13it/s, loss=1.11] \u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:16<01:23,  1.13it/s, loss=1.11]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:16<01:23,  1.13it/s, loss=1.16]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:17<01:22,  1.13it/s, loss=1.16]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:17<01:22,  1.13it/s, loss=0.415]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:18<01:22,  1.13it/s, loss=0.415]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:18<01:22,  1.13it/s, loss=0.483]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:18<01:21,  1.13it/s, loss=0.483]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:18<01:21,  1.13it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:19<01:20,  1.13it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:19<01:20,  1.13it/s, loss=0.762]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:20<01:19,  1.13it/s, loss=0.762]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:20<01:19,  1.13it/s, loss=0.426]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:21<01:18,  1.13it/s, loss=0.426]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:21<01:18,  1.13it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:22<01:17,  1.13it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:22<01:17,  1.13it/s, loss=0.5]  \u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:23<01:16,  1.13it/s, loss=0.5]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:23<01:16,  1.13it/s, loss=0.437]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:24<01:15,  1.13it/s, loss=0.437]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:24<01:15,  1.13it/s, loss=0.621]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:25<01:14,  1.13it/s, loss=0.621]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:25<01:14,  1.13it/s, loss=0.971]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:26<01:14,  1.13it/s, loss=0.971]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:26<01:14,  1.13it/s, loss=0.353]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:26<01:13,  1.13it/s, loss=0.353]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:26<01:13,  1.13it/s, loss=0.431]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:27<01:12,  1.14it/s, loss=0.431]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:27<01:12,  1.14it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:28<01:11,  1.14it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:28<01:11,  1.14it/s, loss=0.437]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:29<01:10,  1.14it/s, loss=0.437]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:29<01:10,  1.14it/s, loss=0.896]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:30<01:09,  1.14it/s, loss=0.896]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:30<01:09,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:31<01:08,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:31<01:08,  1.14it/s, loss=0.818]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:32<01:07,  1.14it/s, loss=0.818]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:32<01:07,  1.14it/s, loss=0.434]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:33<01:06,  1.14it/s, loss=0.434]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:33<01:06,  1.14it/s, loss=0.412]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:33<01:06,  1.14it/s, loss=0.412]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:33<01:06,  1.14it/s, loss=0.62] \u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:34<01:05,  1.13it/s, loss=0.62]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:34<01:05,  1.13it/s, loss=0.453]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:35<01:04,  1.13it/s, loss=0.453]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:35<01:04,  1.13it/s, loss=0.365]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:36<01:03,  1.13it/s, loss=0.365]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:36<01:03,  1.13it/s, loss=0.371]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:37<01:02,  1.14it/s, loss=0.371]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:37<01:02,  1.14it/s, loss=0.545]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:38<01:01,  1.13it/s, loss=0.545]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:38<01:01,  1.13it/s, loss=0.707]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:39<01:00,  1.14it/s, loss=0.707]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:39<01:00,  1.14it/s, loss=0.268]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:40<00:59,  1.14it/s, loss=0.268]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:40<00:59,  1.14it/s, loss=0.987]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:40<00:59,  1.14it/s, loss=0.987]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:41<00:59,  1.14it/s, loss=1.14] \u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:41<00:58,  1.14it/s, loss=1.14]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:41<00:58,  1.14it/s, loss=1.02]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:42<00:57,  1.14it/s, loss=1.02]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:42<00:57,  1.14it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:43<00:56,  1.14it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:43<00:56,  1.14it/s, loss=0.378]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:44<00:55,  1.14it/s, loss=0.378]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:44<00:55,  1.14it/s, loss=0.378]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:45<00:54,  1.14it/s, loss=0.378]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:45<00:54,  1.14it/s, loss=0.648]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:46<00:53,  1.14it/s, loss=0.648]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:46<00:53,  1.14it/s, loss=0.869]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:47<00:52,  1.14it/s, loss=0.869]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:47<00:52,  1.14it/s, loss=0.398]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:48<00:51,  1.14it/s, loss=0.398]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:48<00:51,  1.14it/s, loss=0.28] \u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:48<00:51,  1.14it/s, loss=0.28]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:48<00:51,  1.14it/s, loss=0.469]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:49<00:50,  1.14it/s, loss=0.469]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:49<00:50,  1.14it/s, loss=0.858]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:50<00:49,  1.14it/s, loss=0.858]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:50<00:49,  1.14it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:51<00:48,  1.14it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:51<00:48,  1.14it/s, loss=0.443]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:52<00:47,  1.14it/s, loss=0.443]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:52<00:47,  1.14it/s, loss=1.02] \u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:53<00:46,  1.14it/s, loss=1.02]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:53<00:46,  1.14it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:54<00:45,  1.14it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:54<00:45,  1.14it/s, loss=0.557]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:55<00:44,  1.14it/s, loss=0.557]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:55<00:44,  1.14it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:55<00:43,  1.14it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:55<00:43,  1.14it/s, loss=0.47] \u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [02:56<00:43,  1.14it/s, loss=0.47]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [02:56<00:43,  1.14it/s, loss=0.486]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [02:57<00:42,  1.14it/s, loss=0.486]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [02:57<00:42,  1.14it/s, loss=0.771]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [02:58<00:41,  1.14it/s, loss=0.771]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [02:58<00:41,  1.14it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [02:59<00:40,  1.14it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [02:59<00:40,  1.14it/s, loss=0.495]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [03:00<00:39,  1.14it/s, loss=0.495]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [03:00<00:39,  1.14it/s, loss=0.562]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:01<00:38,  1.14it/s, loss=0.562]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:01<00:38,  1.14it/s, loss=0.772]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:02<00:37,  1.14it/s, loss=0.772]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:02<00:37,  1.14it/s, loss=0.55] \u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:02<00:36,  1.14it/s, loss=0.55]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:02<00:36,  1.14it/s, loss=0.72]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:03<00:35,  1.14it/s, loss=0.72]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:03<00:35,  1.14it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:04<00:35,  1.14it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:04<00:35,  1.14it/s, loss=0.585]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:05<00:34,  1.14it/s, loss=0.585]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:05<00:34,  1.14it/s, loss=0.408]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:06<00:33,  1.14it/s, loss=0.408]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:06<00:33,  1.14it/s, loss=0.574]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:07<00:32,  1.14it/s, loss=0.574]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:07<00:32,  1.14it/s, loss=0.375]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:08<00:31,  1.14it/s, loss=0.375]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:08<00:31,  1.14it/s, loss=1.1]  \u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:09<00:30,  1.14it/s, loss=1.1]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:09<00:30,  1.14it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:09<00:29,  1.14it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:10<00:29,  1.14it/s, loss=0.853]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:10<00:28,  1.14it/s, loss=0.853]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:10<00:28,  1.14it/s, loss=0.814]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:11<00:28,  1.14it/s, loss=0.814]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:11<00:28,  1.14it/s, loss=0.561]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:12<00:27,  1.14it/s, loss=0.561]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:12<00:27,  1.14it/s, loss=0.392]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:13<00:26,  1.14it/s, loss=0.392]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:13<00:26,  1.14it/s, loss=0.621]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:14<00:25,  1.14it/s, loss=0.621]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:14<00:25,  1.14it/s, loss=0.626]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:15<00:24,  1.14it/s, loss=0.626]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:15<00:24,  1.14it/s, loss=0.331]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:16<00:23,  1.14it/s, loss=0.331]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:16<00:23,  1.14it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:17<00:22,  1.14it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:17<00:22,  1.14it/s, loss=0.764]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:17<00:21,  1.14it/s, loss=0.764]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:17<00:21,  1.14it/s, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:18<00:21,  1.14it/s, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:18<00:21,  1.14it/s, loss=0.681]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:19<00:20,  1.14it/s, loss=0.681]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:19<00:20,  1.14it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:20<00:19,  1.14it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:20<00:19,  1.14it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:21<00:18,  1.14it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:21<00:18,  1.14it/s, loss=0.701]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:22<00:17,  1.14it/s, loss=0.701]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:22<00:17,  1.14it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:23<00:16,  1.14it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:23<00:16,  1.14it/s, loss=0.386]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:24<00:15,  1.14it/s, loss=0.386]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:24<00:15,  1.14it/s, loss=0.841]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:24<00:14,  1.14it/s, loss=0.841]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:24<00:14,  1.14it/s, loss=0.501]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:25<00:14,  1.14it/s, loss=0.501]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:25<00:14,  1.14it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:26<00:13,  1.14it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:26<00:13,  1.14it/s, loss=0.978]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:27<00:12,  1.14it/s, loss=0.978]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:27<00:12,  1.14it/s, loss=0.484]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:28<00:11,  1.14it/s, loss=0.484]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:28<00:11,  1.14it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:29<00:10,  1.14it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:29<00:10,  1.14it/s, loss=0.739]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:30<00:09,  1.14it/s, loss=0.739]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:30<00:09,  1.14it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:31<00:08,  1.14it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:31<00:08,  1.14it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:31<00:07,  1.14it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:31<00:07,  1.14it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:32<00:07,  1.14it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:32<00:07,  1.14it/s, loss=0.878]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:33<00:06,  1.14it/s, loss=0.878]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:33<00:06,  1.14it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:34<00:05,  1.14it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:34<00:05,  1.14it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:35<00:04,  1.13it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:35<00:04,  1.13it/s, loss=0.835]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:36<00:03,  1.13it/s, loss=0.835]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:36<00:03,  1.13it/s, loss=0.76] \u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:37<00:02,  1.14it/s, loss=0.76]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:37<00:02,  1.14it/s, loss=0.358]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:38<00:01,  1.14it/s, loss=0.358]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:38<00:01,  1.14it/s, loss=1.22] \u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:39<00:00,  1.14it/s, loss=1.22]\u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:39<00:00,  1.14it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:39<00:00,  1.14it/s, loss=0.638]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [03:54<00:00, 234.26s/it]0,  1.14it/s, loss=0.446]\u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:54<00:00,  1.07it/s, loss=0.619, dist_mean=0.269]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [03:54<00:00, 234.26s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained('aiffel/KoChatGPT/output_2_RM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f82571",
   "metadata": {},
   "source": [
    "## RM 학습 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d767fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "533d9133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 똥멍청이 입니다\n",
      "reward score: -0.6\n"
     ]
    }
   ],
   "source": [
    "input_text = '인공지능은 똥멍청이 입니다'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5395d354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.\n",
      "reward score: -0.6\n"
     ]
    }
   ],
   "source": [
    "input_text = '인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca3a6db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\n",
      "reward score: -0.4\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4154d442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\n",
      "reward score: -0.3\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17aa0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 모델 학습을 위해 할당한 GPU 메모리 초기화\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f816592",
   "metadata": {},
   "source": [
    "# PPO\n",
    "- 학습한 RM을 통해 SFT한 모델을 한번더 Fine-Tuning 하기\n",
    "    - ![PPO](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/rlhf/rlhf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddfa9156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d258a1",
   "metadata": {},
   "source": [
    "## 모델과 옵티마이저 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4eb0d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context(): # Single GPU 환경\n",
    "    # actor, 문장을 생성할 SFT된 모델\n",
    "    actor = GPTActor(pretrained=HOME_DIR + '/aiffel/KoChatGPT/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    # critic, 생성된 문장을 reward 값으로 평가할 RM\n",
    "    critic = GPTCritic(pretrained=HOME_DIR + '/aiffel/KoChatGPT/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    # 토크나이저\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    # 비교군 모델\n",
    "    initial_model = deepcopy(actor)\n",
    "    # PPO로 학습할 모델\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bee84321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor를 학습시킬 옵티마이저\n",
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "# critic을 학습시킬 옵티마이저\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83dea232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single GPU 환경에 맞춰 모델과 옵티마이저 세팅\n",
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2d3792",
   "metadata": {},
   "source": [
    "## PPO 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3686ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME_DIR + '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a93a08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[47311, 10448, 19008,  9792, 11780, 11308, 30190, 10929, 11849, 21663,\n",
      "         44389,  9574, 13799,   458, 14308, 12778, 22469, 20938, 44696,   458,\n",
      "         13799,   458, 14308, 12778, 11756, 18944,   389]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "# 토크나이징 함수 확인\n",
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2907c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO 데이터셋 크기: 12000\n"
     ]
    }
   ],
   "source": [
    "print(\"PPO 데이터셋 크기:\", len(list_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb32c9",
   "metadata": {},
   "source": [
    "## PPO Trainer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43b33113",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef653d0",
   "metadata": {},
   "source": [
    "## PPO 학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc8eafd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.81s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.000422]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.92it/s, actor_loss=0, critic_loss=0.000422]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.92it/s, actor_loss=0, critic_loss=0.107]   \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=0, critic_loss=0.107]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.93it/s, actor_loss=0, critic_loss=0.00651]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.92it/s, actor_loss=0, critic_loss=0.00651]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:18<00:00,  6.33s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.91s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.16, critic_loss=0.0223]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.85it/s, actor_loss=0.16, critic_loss=0.0223]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.85it/s, actor_loss=0.217, critic_loss=0.069]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0.217, critic_loss=0.069]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0.151, critic_loss=0.0428]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.85it/s, actor_loss=0.151, critic_loss=0.0428]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:19<00:00,  6.45s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.02s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.107, critic_loss=0.0138]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.107, critic_loss=0.0138]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.104, critic_loss=0.000928]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.104, critic_loss=0.000928]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0981, critic_loss=0.0164] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=0.0981, critic_loss=0.0164]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:19<00:00,  6.52s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.91s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.162, critic_loss=0.028]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.86it/s, actor_loss=-.162, critic_loss=0.028]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.86it/s, actor_loss=-.161, critic_loss=0.0255]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.161, critic_loss=0.0255]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.154, critic_loss=0.0137]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=-.154, critic_loss=0.0137]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:19<00:00,  6.41s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.75s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0409, critic_loss=0.00134]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.0409, critic_loss=0.00134]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.0425, critic_loss=0.00197]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.0425, critic_loss=0.00197]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.89it/s, actor_loss=-.0451, critic_loss=0.00644]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=-.0451, critic_loss=0.00644]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:18<00:00,  6.33s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.81s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.126, critic_loss=0.0173]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.86it/s, actor_loss=0.126, critic_loss=0.0173]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.86it/s, actor_loss=0.137, critic_loss=0.013] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.137, critic_loss=0.013]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.126, critic_loss=0.00819]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=0.126, critic_loss=0.00819]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:19<00:00,  6.38s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.86s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0122, critic_loss=0.00099]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.0122, critic_loss=0.00099]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.0165, critic_loss=0.000773]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0165, critic_loss=0.000773]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0218, critic_loss=0.00554] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.0218, critic_loss=0.00554]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:19<00:00,  6.42s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.82s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0864, critic_loss=0.00802]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.86it/s, actor_loss=-.0864, critic_loss=0.00802]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.86it/s, actor_loss=-.0912, critic_loss=0.0106] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0912, critic_loss=0.0106]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0894, critic_loss=0.0036]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-.0894, critic_loss=0.0036]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:19<00:00,  6.36s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:10<00:05,  5.20s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.023, critic_loss=0.000351]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.86it/s, actor_loss=-.023, critic_loss=0.000351]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.86it/s, actor_loss=-.0271, critic_loss=0.000352]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0271, critic_loss=0.000352]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0295, critic_loss=0.0034]  \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-.0295, critic_loss=0.0034]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:17<00:00,  5.99s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.82s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0656, critic_loss=0.00473]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.86it/s, actor_loss=0.0656, critic_loss=0.00473]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.86it/s, actor_loss=0.0507, critic_loss=0.00383]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0507, critic_loss=0.00383]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.0737, critic_loss=0.00341]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.0737, critic_loss=0.00341]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:17<00:00,  5.86s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "model.save_pretrained('aiffel/KoChatGPT/output_3_PPO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d7d6d5",
   "metadata": {},
   "source": [
    "## PPO 학습 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12f79641",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이므로 제가 어떤 종류의 쇠고기를 판매하는지 알 수 없습니다. 죄송합니다. srkin (쇠고기) 추가 정보가 필요합니다. 불고기용 한우는 불고기용 부위를 말합니다. geos, 또는 kinhungsin에서 각각 다른 이름입니다. geos, 또는 geos, 혹은 kinhungsin에서는 다양한 이름으로 사용됩니다. geos, 또는  Kinhungsin은 각각 다른 이름으로 사용되기도 합니다.  ninglawaid에서 각각 다른 이름으로 사용될 수 있습니다. geos, 또는  Ninglawaid에서는 주로 불고기용으로 사용되는 경우가 많습니다. geos, 또는 geos는 각각 다른 이름으로 사용될 수 있습니다. geos, 또는 geos는 각각 다른 이름으로 쓰일 수 있습니다. geos, 또는 geos는 각각 다른 이름으로 사용되기도 합니다. neos, 또는 \n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):\"저는 데이터에 대한 의존도를 가지고 있지 않기 때문에 제임스 닉슨의 부통령직에서 근무한 기간도에 대해 알지 못합니다. 정확한 정보와 관련해서는 \"리처드 닉슨의 47대 부통령직\"이라는 개인의 이름이나 연도, 인물 정보에 대한 정보가 없습니다.\", 'token': 147}自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由自由\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이므로 시카고에 있는 국제공항 정보나 위치 정보가 없습니다. 하지만 현재 시카고에는 수많은 공항이 있으므로 이 정보를 토대로 정보를 얻으실 수 있습니다.神明神話題: \"시카고 오헤어 국제공항은 어디에 있어?\" 究算神話題: \"시카고에 위치한 국제공항은 어디로 가고 있나?\"라는 문맥에서 언급됩니다. 究算神話題: \"시카고에 위치한 국제공항은?\"라는 문맥에서 언급됩니다.神話題: \"시카고에 위치한 국제공항은 어디로 가고 있는지에 따라?\"라는 문맥에서 언급됩니다.神話題: \"이 국제공항은이런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런저런\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'미세먼지 때문에 걱정된다면 대중교통, 생활 밀접물, 음식물류 등의 분야로 대처하는 것이 좋습니다. 또한, 미세먼지를 줄이기 위해 실내에서 미세먼지를 제거하는 것도 도움이 될 수 있습니다. 또한, 미세먼지 발생 시 마스크 착용 등의 예방책과 손세탁 등으로 미세먼지를 줄이는 방법을 통해 미세먼지가 줄어들기 쉽습니다.\\n\\n또한, 미세먼지는 우리가 건강하지 않은 환경에서는 오히려 불쾌한 환경이기 때문에 주의가 필요합니다.\\n\\n마스크는 미세먼지 제거가 중요하지만, 미세먼지 발생 시 마스크 착용은 필수적인 것이며, 마스크를 착용하지 않으면 건강을 잃는 것이 불가피합니다. 身間なな間間, all\\n\\n그러나 이런 상황에서는 대중교통, 생활밀착물, 음식물류 등에 대한 예방책이 필요합니다. all\\n마스크 착용, 손세탁 등 다양한 방법으로 미세먼지를 줄이는 것이 도움이 됩니다. all\\n하지만 실제로 미세먼지라는 상황에 대처하기 위해서는 각 산업분야의 기술 개발과 관리체계가 잘 확립\n"
     ]
    }
   ],
   "source": [
    "# 답변 생성 함수\n",
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "# 지시문\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# 테스트용 질문 문장\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "# 질문 문장에 지시문 추가\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "# 질문에 따른 답변 생성\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab946b",
   "metadata": {},
   "source": [
    "# 회고\n",
    "- RLHF를 더 자세히 알 수 있었음\n",
    "    - 처음에는 모델의 모든 대답을 사람이 평가하는 것으로 생각함\n",
    "    - 하지만 일부 데이터셋에서만 라벨링을 한 후에 Reward Model을 만드는 방식이 신박하게 느껴짐\n",
    "- LLM에 와서는 이제 학습 환경에 대해 신경을 써야함\n",
    "    - 이제는 하나의 모델을 Fine-Tuning하는 것 조차 여러개의 모델을 필요로 함\n",
    "    - GPU 환경에서 어떻게 학습할지 결정하기 위해서는 모델 학습이나 추론은 GPU에게 어떻게 맡기는지에 대한 지식이 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b8aabb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
